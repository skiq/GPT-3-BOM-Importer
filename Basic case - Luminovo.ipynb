{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import excel2json\n",
    "import jsonlines \n",
    "import os       \n",
    "import openai \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment\n",
    "# Load your API key from an environment variable named as OPENAI_API_KEY\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel -> Json -> load Json to python as dictionary -> convert to str -> make jsonl -> send to GPT3\n",
    "file : Bill of Materials-AR403__LABEL.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|███████████████████████████████████████████████████████████| 21.2k/21.2k [00:00<00:00, 40.3kit/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<File file id=file-Szgpq0tBGYM98mrsTPrMx5sB at 0x26ec5a52dc8> JSON: {\n",
       "  \"bytes\": 20893,\n",
       "  \"created_at\": 1618497587,\n",
       "  \"filename\": \"Labelled Data\\\\gpt3_format_BOM_AR403.jsonl\",\n",
       "  \"id\": \"file-Szgpq0tBGYM98mrsTPrMx5sB\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"answers\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting Excel to json file \n",
    "excel2json.convert_from_file(r'Labelled Data\\Bill of Materials-AR403__LABEL.xlsx')\n",
    "\n",
    "#loading json file as python dictionary\n",
    "BOM_AR403 = open(r'Labelled Data\\Sheet1.json',)\n",
    "BOM_AR403_dict = json.load(BOM_AR403)\n",
    "\n",
    "#Convert to str and put it in the GPT3 accessible file format : {\"text\":\"...\",\"metadata\":\"...\"}\n",
    "gpt3_format_BOM_AR403 = { \"text\" : str(BOM_AR403_dict), \"metadata\" : \"\"}\n",
    "\n",
    "#Convert to jsonl for sending it to GPT3 File\n",
    "with jsonlines.open(r'Labelled Data\\gpt3_format_BOM_AR403.jsonl', 'w') as writer:\n",
    "    writer.write(gpt3_format_BOM_AR403)\n",
    "\n",
    "# create file\n",
    "openai.File.create(file=open(r'Labelled Data\\gpt3_format_BOM_AR403.jsonl'), purpose='answers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-Szgpq0tBGYM98mrsTPrMx5sB at 0x26ec5d06f48> JSON: {\n",
       "  \"bytes\": 20893,\n",
       "  \"created_at\": 1618497587,\n",
       "  \"filename\": \"Labelled Data\\\\gpt3_format_BOM_AR403.jsonl\",\n",
       "  \"id\": \"file-Szgpq0tBGYM98mrsTPrMx5sB\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"answers\",\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the file is retrievable and error free\n",
    "openai.File.retrieve('file-Szgpq0tBGYM98mrsTPrMx5sB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### status : processed (we are good to go...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The document at index 1 is 6304 tokens over the length limit of 1994. If you would like us to add a feature to auto-truncate server-side, let us know at support@openai.com.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3f17aed00889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     [\"What is the value of MPN where Designators is  XP2 and Qty is 1.0\",\"No value found\"]],\n\u001b[0;32m      9\u001b[0m     \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"<|endoftext|>\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\answer.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, **params)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"answers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\openai_object.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream, plain_old_data)\u001b[0m\n\u001b[0;32m    242\u001b[0m         )\n\u001b[0;32m    243\u001b[0m         response, stream, api_key = requestor.request(\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         )\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    356\u001b[0m             )\n\u001b[0;32m    357\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m             raise self.handle_error_response(\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m             )\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The document at index 1 is 6304 tokens over the length limit of 1994. If you would like us to add a feature to auto-truncate server-side, let us know at support@openai.com."
     ]
    }
   ],
   "source": [
    "#Bring GPT3 into action\n",
    "openai.Answer.create( \n",
    "    model=\"davinci\", \n",
    "    question=\"What is the value of MPN where Designators is R1, R5, R12, R13, R20, R53, R55, R57 and Qty is  8.0\", \n",
    "    file=\"file-Szgpq0tBGYM98mrsTPrMx5sB\", \n",
    "    examples_context=\" \\\"OrigExcelRowNumber\\\": 73.0, \\\"Designators\\\": \\\"IC12\\\", \\\"Qty\\\": 1.0, \\\"Unit\\\": \\\"Pieces\\\", \\\"DNP\\\": 0, \\\"CPN\\\": \\\"\\\", \\\"MPN\\\": \\\"TPS54360DDA\\\", \\\"Manufacturer\\\": \\\"TEXAS INSTRUMENTS\\\", \\\"isManufacturerFree\\\": 0, \\\"ResistorProperties\\\": \\\"\\\", \\\"CapacitorProperties\\\": \\\"\\\", \\\"OtherProperties\\\": \\\"60V ; 3.5 A\\\", \\\"Package\\\": \\\"HSOP-8\\\", \\\"Description\\\": \\\"60V Input, 3.5 A, Step Down DC-DC Converter\\\", \\\"Comment\\\": \\\"\\\"}\\n{\\\"OrigExcelRowNumber\\\": 16.0, \\\"Designators\\\": \\\"R1, R5, R12, R13, R20, R53, R55, R57\\\", \\\"Qty\\\": 8.0, \\\"Unit\\\": \\\"Pieces\\\", \\\"DNP\\\": 0, \\\"CPN\\\": \\\"\\\", \\\"MPN\\\": \\\"\\\", \\\"Manufacturer\\\": \\\"\\\", \\\"isManufacturerFree\\\": 1, \\\"ResistorProperties\\\": \\\"1k\\\", \\\"CapacitorProperties\\\": \\\"\\\", \\\"OtherProperties\\\": \\\"\\\", \\\"Package\\\": \\\"0805\\\", \\\"Description\\\": \\\"Resistor\\\", \\\"Comment\\\": \\\"\\\"}\\n{\\\"OrigExcelRowNumber\\\": 18.0, \\\"Designators\\\": \\\"C15, C16, C18, C19, C20, C34\\\", \\\"Qty\\\": 6.0, \\\"Unit\\\": \\\"Pieces\\\", \\\"DNP\\\": 0, \\\"CPN\\\": \\\"\\\", \\\"MPN\\\": \\\"\\\", \\\"Manufacturer\\\": \\\"\\\", \\\"isManufacturerFree\\\": 1, \\\"ResistorProperties\\\": \\\"\\\", \\\"CapacitorProperties\\\": \\\"1µF\\\", \\\"OtherProperties\\\": \\\"\\\", \\\"Package\\\": \\\"0805\\\", \\\"Description\\\": \\\"Capacitor\\\", \\\"Comment\\\": \\\"\\\"}\\n{\\\"OrigExcelRowNumber\\\": 23.0, \\\"Designators\\\": \\\"XP2\\\", \\\"Qty\\\": 1.0, \\\"Unit\\\": \\\"Pieces\\\", \\\"DNP\\\": 0, \\\"CPN\\\": \\\"\\\", \\\"MPN\\\": \\\"\\\", \\\"Manufacturer\\\": \\\"\\\", \\\"isManufacturerFree\\\": 1, \\\"ResistorProperties\\\": \\\"\\\", \\\"CapacitorProperties\\\": \\\"\\\", \\\"OtherProperties\\\": \\\"2.5 MSF 04\\\", \\\"Package\\\": \\\"\\\", \\\"Description\\\": \\\"Connector\\\", \\\"Comment\\\":\\\"\\\" \", \n",
    "    examples=[[\"What is the value of MPN where Designators is IC12 and Qty is  1.0\",\"TPS54360DDA\"],\n",
    "    [\"What is the value of MPN where Designators is  XP2 and Qty is 1.0\",\"No value found\"]],\n",
    "    max_tokens=10,\n",
    "    stop=[\"\\n\", \"<|endoftext|>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
